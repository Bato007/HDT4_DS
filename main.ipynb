{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import string, re, emoji\n",
    "\n",
    "# Limpieza de textos\n",
    "from pattern.text.en import singularize, lemma\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  id - a unique identifier for each tweet\n",
    "  text - the text of the tweet\n",
    "  location - the location the tweet was sent from (may be blank)\n",
    "  keyword - a particular keyword from the tweet (may be blank)\n",
    "  target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)\n",
    "'''\n",
    "train = pd.read_csv('./train.csv', encoding='utf8')\n",
    "\n",
    "cachedStopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['location'].value_counts().head(10).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['keyword'].value_counts().head(10).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanCountry(value):\n",
    "  try:\n",
    "\n",
    "    if (\n",
    "      'nan' in value or\n",
    "      'world' in value or\n",
    "      'global' in value or\n",
    "      'everywhere' in value or\n",
    "      'earth' in value or\n",
    "      'ss' in value or\n",
    "      '?' in value or\n",
    "      re.search(r\"[0-9]+\", value, re.I)\n",
    "    ):\n",
    "      return 'unknow'\n",
    "\n",
    "    if (\n",
    "      'italy' in value\n",
    "    ):\n",
    "      return 'italy'\n",
    "\n",
    "    if (\n",
    "      'india' in value or\n",
    "      'mumbai' in value\n",
    "    ):\n",
    "      return 'india'\n",
    "    \n",
    "    if (\n",
    "      'switzerland' in value or\n",
    "      'geneva' in value\n",
    "    ):\n",
    "      return 'switzerland'\n",
    "    \n",
    "    if (\n",
    "      'china' in value or\n",
    "      'hong kong' in value\n",
    "    ):\n",
    "      return 'china'\n",
    "\n",
    "    if (\n",
    "      'nigeria' in value or\n",
    "      'lagos' in value\n",
    "    ):\n",
    "      return 'nigeria'\n",
    "\n",
    "    if (\n",
    "      'japan' in value or\n",
    "      'tokyo' in value\n",
    "    ):\n",
    "      return 'japan'\n",
    "\n",
    "    if (\n",
    "      'ontario' in value or\n",
    "      'canada' in value or\n",
    "      'toronto' in value or\n",
    "      'calgary' in value or\n",
    "      'alberta' in value or\n",
    "      re.search(r\"ab$\", value, re.I) or\n",
    "      re.search(r\"bc$\", value, re.I)\n",
    "    ):\n",
    "      return 'canada'\n",
    "\n",
    "    if (\n",
    "      'uk' == value or\n",
    "      'united kingdom' in value or\n",
    "      'kingdom' in value or\n",
    "      'british' in value or\n",
    "      'scotland' in value or\n",
    "      'newcastle' in value or\n",
    "      'england' in value or\n",
    "      'london' in value or\n",
    "      re.search(r\"uk$\", value, re.I)\n",
    "    ):\n",
    "      return 'uk'\n",
    "\n",
    "    if (\n",
    "      'nyc' == value or\n",
    "      'nj' == value or\n",
    "      'united states' in value or\n",
    "      'new york' in value or\n",
    "      'san francisco' in value or\n",
    "      'los angeles' in value or\n",
    "      'new jersey' in value or\n",
    "      'north carolina' in value or\n",
    "      'st. louis' in value or\n",
    "      'kansas city' in value or\n",
    "      'san diego' in value or\n",
    "      'las vegas' in value or\n",
    "      'sacramento' in value or\n",
    "      'oregon' in value or\n",
    "      'michigan' in value or\n",
    "      'manchester' in value or\n",
    "      'portland' in value or\n",
    "      'texas' in value or\n",
    "      'u.s.' in value or\n",
    "      'philippines' in value or\n",
    "      'nevada' in value or\n",
    "      'us' in value or\n",
    "      'arizona' in value or\n",
    "      'lincoln' in value or\n",
    "      'wisconsin' in value or\n",
    "      'pennsylvania' in value or\n",
    "      'seattle' in value or\n",
    "      'usa' in value or\n",
    "      'washington' in value or\n",
    "      'florida' in value or\n",
    "      'chicago' in value or\n",
    "      'california' in value or\n",
    "      'nashville' in value or\n",
    "      'colorado' in value or\n",
    "      'denver' in value or\n",
    "      'cleveland' in value or\n",
    "      'atlanta' in value or\n",
    "      'massachusetts' in value or\n",
    "      'boston' in value or\n",
    "      'oklahoma' in value or\n",
    "      'tennessee' in value or\n",
    "      'liverpool' in value or\n",
    "      'phoenix' in value or\n",
    "      'baltimore' in value or\n",
    "      re.search(r\"nyc$\", value, re.I) or\n",
    "      re.search(r\"hi$\", value, re.I) or\n",
    "      re.search(r\"va$\", value, re.I) or\n",
    "      re.search(r\"ks$\", value, re.I) or\n",
    "      re.search(r\"la$\", value, re.I) or\n",
    "      re.search(r\"ak$\", value, re.I) or\n",
    "      re.search(r\"md$\", value, re.I) or\n",
    "      re.search(r\"mo$\", value, re.I) or\n",
    "      re.search(r\"wi$\", value, re.I) or\n",
    "      re.search(r\"az$\", value, re.I) or\n",
    "      re.search(r\"ga$\", value, re.I) or\n",
    "      re.search(r\"ok$\", value, re.I) or\n",
    "      re.search(r\"nj$\", value, re.I) or\n",
    "      re.search(r\"wa$\", value, re.I) or\n",
    "      re.search(r\"pa$\", value, re.I) or\n",
    "      re.search(r\"ma$\", value, re.I) or\n",
    "      re.search(r\"co$\", value, re.I) or\n",
    "      re.search(r\"oh$\", value, re.I) or\n",
    "      re.search(r\"il$\", value, re.I) or\n",
    "      re.search(r\"tn$\", value, re.I) or\n",
    "      re.search(r\"dc$\", value, re.I) or\n",
    "      re.search(r\"ca$\", value, re.I) or\n",
    "      re.search(r\"tx$\", value, re.I) or\n",
    "      re.search(r\"nc$\", value, re.I) or\n",
    "      re.search(r\"fl$\", value, re.I) or\n",
    "      re.search(r\"ny$\", value, re.I)\n",
    "    ):\n",
    "      return 'usa'\n",
    "\n",
    "    return value\n",
    "  except:\n",
    "    return 'unknow'\n",
    "\n",
    "train['location'] = train['location'].apply(lambda row: str(row).lower())\n",
    "train['location'] = train['location'].apply(lambda row: cleanCountry(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toSingular(value):\n",
    "  try:\n",
    "    return singularize(value)\n",
    "  except:\n",
    "    return value\n",
    "\n",
    "def parseLemma(value):\n",
    "  try:\n",
    "    return lemma(value)\n",
    "  except:\n",
    "    return value\n",
    "\n",
    "def replaceSpace(value):\n",
    "  return str(value).replace('%20', ' ')\n",
    "\n",
    "train['keyword'] = train['keyword'].apply(lambda row: toSingular(row))\n",
    "train['keyword'] = train['keyword'].apply(lambda row: parseLemma(row))\n",
    "train['keyword'] = train['keyword'].apply(lambda row: replaceSpace(row))\n",
    "train['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeHastags(value):\n",
    "  if ('#' not in value): return value\n",
    "  hashtags = re.findall(r\"#[^\\s]*\", value, re.I)\n",
    "  for hashtag in hashtags:\n",
    "    value = value.replace(hashtag, '')\n",
    "  return value\n",
    "\n",
    "def removeLinks(value):\n",
    "  if ('http' not in value): return value\n",
    "  links = re.findall(r\"http[^\\s]*\", value, re.I)\n",
    "  for link in links:\n",
    "    value = value.replace(link, '')\n",
    "  return value\n",
    "\n",
    "def removeStepWords(value):\n",
    "  return ' '.join([word for word in value.split() if word not in cachedStopWords])\n",
    "\n",
    "def extractEmojis(value):\n",
    "  items = value.split(' ')\n",
    "  emojis = ''.join(item for item in items if item in emoji.EMOJI_DATA)\n",
    "\n",
    "  if (len(emojis) > 0): print(value)\n",
    "\n",
    "  return value\n",
    "\n",
    "def sentenceToSingular(value):\n",
    "  items = value.split(' ')\n",
    "  for item in items:\n",
    "    singular = toSingular(item)\n",
    "    value = value.replace(item, singular)\n",
    "  return value\n",
    "\n",
    "def sentenceToPresent(value):\n",
    "  items = value.split(' ')\n",
    "  for item in items:\n",
    "    present = parseLemma(item)\n",
    "    value = value.replace(item, present)\n",
    "  return value\n",
    "\n",
    "translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "\n",
    "cleanText = []\n",
    "for index, row in train.iterrows():\n",
    "  text = row['text'][:]\n",
    "\n",
    "  # Limpiando el texto\n",
    "  text = text.lower()                         # Convierte todo a minusculas\n",
    "  text = text.replace('#', '')                # Quita #\n",
    "  text = text.replace('@', '')                # Quita @\n",
    "  text = removeLinks(text)                    # Quita links\n",
    "  text = text.translate(translator)           # Quita todos los signos de puntuacion\n",
    "  text = removeStepWords(text)                # Quita todas las step words\n",
    "  text = extractEmojis(text)                  # Quita todos los emojis\n",
    "  text = re.sub(' +', ' ', text)              # Quita todos los espacios de mas\n",
    "  text = sentenceToSingular(text)             # Pasa las palabras a singular\n",
    "  text = sentenceToPresent(text)              # Pasa las palabras a presente\n",
    "  \n",
    "  numbers = re.findall(r\"[0-9]+\", text, re.I)\n",
    "  if (len(numbers) > 0):\n",
    "    for number in numbers:\n",
    "      if (number == '911'): continue\n",
    "\n",
    "      # Quitando numeros\n",
    "      text = text.replace(number, '')\n",
    "\n",
    "  text = text.replace('utc', '')              # Quita utc\n",
    "  text = removeStepWords(text)                # Quita todas las step words\n",
    "  text = re.sub(' +', ' ', text)              # Quita todos los espacios de mas\n",
    "\n",
    "  cleanText.append(text)\n",
    "\n",
    "train['text'] = cleanText[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['target']\n",
    "train = train.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['keyword'].value_counts().head(10).plot.bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a8e74bc410295dd7b3e2a92a04bda485b935e7c35103812674b9cdd1b25ea1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
